nominales <- which( tipoDatos == "factor") # categoricas
ordinales <- which( sapply(student_scores, is.ordered) )  # ordinales
categoricas <- c(nominales, ordinales)
vars_predict <- c('math_score','history_score','physics_score',"chemistry_score","biology_score","english_score","geography_score")  #covariables
dependiente <- "weekly_self_study_hours" #variable explicada o dependiente
multi.hist(student_scores[, vars_predict]) # Histogramas con formato de funciones.R
pairs(student_scores[,vars_predict])
#par(mfrow = c(3, 3))
plot(student_scores$math_score,col="red",main = "Calificaciones en Matematicas",ylab = "Score")
plot(student_scores$history_score,col="blue",main = "Calificaciones Historia",ylab = "Score")
plot(student_scores$physics_score,col="cyan",main = "Calificaciones Fisica",ylab = "Score")
plot(student_scores$chemistry_score,col="seagreen",main = "Calificaciones Quimica",ylab = "Score")
plot(student_scores$biology_score,col="green",main = "Calificaciones Biologia",ylab = "Score")
plot(student_scores$english_score,col="magenta",main = "Calificaciones Ingles",ylab = "Score")
plot(student_scores$geography_score,col="orange",main = "Calificaciones Geografia",ylab = "Score")
par(bty = "n")
boxplot(student_scores[,vars_predict],main = "Boxplot de variables predictoras",las = 3,cex=0.6,cex.main = 0.8,cex.axis = 0.55, col = "red", border = "black")
KMO(student_scores[,vars_predict])
comps <- princomp(student_scores[,vars_predict])
summary(comps)
fit <- MVN::mvn(data = comps$scores, mvnTest = "hz", multivariateOutlierMethod = "quan")
#### scores: La muestra aleatoria de las ccomponentes ppales
#### loadings:  Matriz Gamma
comps$loadings
#### scores: La muestra aleatoria de las ccomponentes ppales
comps$scores
#### scores: La muestra aleatoria de las ccomponentes ppales
comps$scores(head)
#### scores: La muestra aleatoria de las ccomponentes ppales
head(comps$scores, 10)
#fit <- MVN::mvn(data = comps$scores, mvnTest = "hz", multivariateOutlierMethod = "quan")
ajuste <- MVN::mvn(data = as.matrix(predictoras.princomp$scores), mvnTest="hz", multivariateOutlierMethod="quan")
#fit <- MVN::mvn(data = comps$scores, mvnTest = "hz", multivariateOutlierMethod = "quan")
ajuste <- MVN::mvn(data = as.matrix(comps$scores), mvnTest="hz", multivariateOutlierMethod="quan")
knitr::opts_chunk$set(echo = TRUE)
source("funciones.R")
library(tidyverse)
library(caret)
library(car)
library(MASS)
library(factoextra)
library(FactoMineR)
library(repr)
library(psych)
datos <- read.csv("DataSets/student-scores.csv")
tipoDatos <- sapply(datos, class) # Saber los tipos de datos
continuas <-  which(tipoDatos == "numeric") # continuas
enteras <- which(tipoDatos == "integer") # enteras
numericas <- c(continuas,enteras)
nominales <- which( tipoDatos == "factor") # categoricas
ordinales <- which( sapply(datos, is.ordered) )  # ordinales
categoricas <- c(nominales, ordinales)
predictoras <-c('math_score',	'history_score',	'physics_score',	'chemistry_score',	'biology_score',	'english_score',	'geography_score')
tarjet <- "weekly_self_study_hours"
multi.hist(datos[, predictoras]) # Histogramas
pairs(datos[, predictoras]) # Dispersiones
# Grafico de Caja y Bigotes
par(bty = "n")
boxplot(datos[, predictoras], main="Grafico de caja y bigotes",
las = 2, cex=0.4, cex.main=1, cex.axis = 0.7, col = "sky blue", border= "black");grid()
datos[, predictoras]
KMO(datos[, predictoras])
predictoras.princomp <- princomp(datos[,predictoras])
predictoras.princomp$loadings # Matriz Gamma
predictoras.princomp$scores # La muestra aleatoria de las ccomponentes ppales
summary(predictoras.princomp)
ajuste <- MVN::mvn(data = as.matrix(predictoras.princomp$scores), mvnTest="hz", multivariateOutlierMethod="quan")
knitr::opts_chunk$set(echo = T, fig.width = 6, fig.height = 3.5)
#rm(list = ls())
pacman::p_load(tidyverse,
kableExtra,
cowplot,
stargazer,knitr,viridis,dplyr,readr,scales,quantmod,texreg,tinytex,
tidyr, imager,lubridate,tseries, astsa, growthrates, tis, dynlm,
readxl, foreign, hrbthemes, gtsummary, corrplot, lm.beta, ggfortify,
AER, lmtest, sandwich,GGally, ggplot2, car, psych, FactoMineR, factoextra,
caret, MASS, repr)
source("funciones.R") #funciones auxiliares prediseñadas
#Cargamos la base de datos
student_scores <- read.csv("DataSets/student-scores.csv") #con read_csv no reconoce como numéricos
summary(student_scores) #Estadística descriptiva de los datos
tipoDatos <- sapply(student_scores, class) # Saber los tipos de datos
continuas <-  which(tipoDatos == "numeric") # continuas
enteras <- which(tipoDatos == "integer") # enteras
numericas <- c(continuas,enteras)
nominales <- which( tipoDatos == "factor") # categoricas
ordinales <- which( sapply(student_scores, is.ordered) )  # ordinales
categoricas <- c(nominales, ordinales)
vars_predict <- c('math_score','history_score','physics_score',"chemistry_score","biology_score","english_score","geography_score")  #covariables
dependiente <- "weekly_self_study_hours" #variable explicada o dependiente
multi.hist(student_scores[, vars_predict]) # Histogramas con formato de funciones.R
pairs(student_scores[,vars_predict])
#par(mfrow = c(3, 3))
plot(student_scores$math_score,col="red",main = "Calificaciones en Matematicas",ylab = "Score")
plot(student_scores$history_score,col="blue",main = "Calificaciones Historia",ylab = "Score")
plot(student_scores$physics_score,col="cyan",main = "Calificaciones Fisica",ylab = "Score")
plot(student_scores$chemistry_score,col="seagreen",main = "Calificaciones Quimica",ylab = "Score")
plot(student_scores$biology_score,col="green",main = "Calificaciones Biologia",ylab = "Score")
plot(student_scores$english_score,col="magenta",main = "Calificaciones Ingles",ylab = "Score")
plot(student_scores$geography_score,col="orange",main = "Calificaciones Geografia",ylab = "Score")
par(bty = "n")
boxplot(student_scores[,vars_predict],main = "Boxplot de variables predictoras",las = 3,cex=0.6,cex.main = 0.8,cex.axis = 0.55, col = "red", border = "black")
KMO(student_scores[,vars_predict])
comps <- princomp(student_scores[,vars_predict])
summary(comps)
#### loadings:  Matriz Gamma
comps$loadings
#### scores: La muestra aleatoria de las ccomponentes ppales
head(comps$scores, 10)
#fit <- MVN::mvn(data = comps$scores, mvnTest = "hz", multivariateOutlierMethod = "quan")
ajuste <- MVN::mvn(data = as.matrix(comps$scores), mvnTest="hz", multivariateOutlierMethod="quan")
plot(comps$scores[,c(1,2)], col = "blue4", main = "Gráfico con 2 componentes")
biplot(comps)
biplot(comps)
install.packages("scatterplot3d")
knitr::opts_chunk$set(echo = T, fig.width = 6, fig.height = 3.5)
#rm(list = ls())
pacman::p_load(tidyverse,
kableExtra,
cowplot,
stargazer,knitr,viridis,dplyr,readr,scales,quantmod,texreg,tinytex,
tidyr, imager,lubridate,tseries, astsa, growthrates, tis, dynlm,
readxl, foreign, hrbthemes, gtsummary, corrplot, lm.beta, ggfortify,
AER, lmtest, sandwich,GGally, ggplot2, car, psych, FactoMineR, factoextra,
caret, MASS, repr,scatterplot3d)
scatterplot3d(comps$scores[,c(1,2)])
scatterplot3d(comps$scores[,c(1,2)], color="steelblue")
colors <- c("#999999", "#E69F00", "#56B4E9")
scatterplot3d(comps$scores[,c(1,2)], color=colors)
scatterplot3d(comps$scores[,c(1,2)], color="steelblue")
scatterplot3d(comps$scores[,c(1,3)], color="steelblue")
#text(s3d$xyz.convert(comps[, 1:3]), labels = rownames(iris), cex= 0.7, col = "steelblue")
View(comps)
scatterplot3d(comps$scores[,c(1,2)], color="steelblue")
#text(s3d$xyz.convert(comps[, 1:3]), labels = rownames(iris), cex= 0.7, col = "steelblue")
scatterplot3d(comps$scores[,c(1,3)], color="steelblue")
#text(s3d$xyz.convert(comps[, 1:3]), labels = rownames(iris), cex= 0.7, col = "steelblue")
scatterplot3d(comps$scores[,c(1,3)], color="steelblue")
text(s3d$xyz.convert(comps[, 1:3]), labels = rownames(comps$scores), cex= 0.7, col = "steelblue")
scatterplot3d(comps$scores[,c(1,3)], color="steelblue")
text(s3d$xyz.convert(comps[, 1:3]), labels = rownames(comps), cex= 0.7, col = "steelblue")
scatterplot3d(comps$scores[,c(1,3)], color="steelblue")
text(s3d$xyz.convert(comps[, 1:3]), labels = rownames(comps$scores), cex= 0.7, col = "steelblue")
scatterplot3d(comps$scores[,c(1,3)], color="steelblue")
text(s3d$xyz.convert(comps[, 1:3]), labels = rownames(comps$scores[,c(1,3)]), cex= 0.7, col = "steelblue")
scatterplot3d(comps$scores[,c(1,3)], color="steelblue")
install.packages("klaR")
libraqry(klaR)
library(klaR)
triplot(x = comps$scores[1], y = comps$scores[2], z = comps$scores[3], main = "", frame = TRUE,
label = 1:3, grid = seq(0.1, 0.9, by = 0.1), center = FALSE,
set.par = TRUE, ...)
library(klaR)
triplot(x = comps$scores[1], y = comps$scores[2], z = comps$scores[3], main = "", frame = TRUE)
install.packages("triplot")
obj.PCA$desc <- dimdesc(obj.PCA, axes = c(1,2), proba = 0.05)
pca_comps <- PCA(student_scores[,vars_predict],scale.unit = T, ncp = 3, graph = T) #FactoMineR package
fviz_cos2(pca_comps,choice = "var",axes = 2)#factoextra package
obj.PCA$desc <- dimdesc(obj.PCA, axes = c(1,2), proba = 0.05)
obj.PCA$desc <- dimdesc(pca_comps, axes = c(1,2), proba = 0.05)
pca_comps$desc <- dimdesc(pca_comps, axes = c(1,2), proba = 0.05)
pca_comps$desc$Dim.1
pca_comps$desc$Dim.2
#Correr esto con la libreria
pca_comps <- PCA(student_scores[,vars_predict],scale.unit = TRUE, ncp = 3, graph = T) #mover el parametro de ncp para el numero de componentes principales y que se conserve al menos el 80% de variabilidad.
fviz_cos2(comps, choice = "var", axes = 2) #cambiar comps por pca_comps
pca_comps$desc <- dimdesc(pca_comps, axes = c(1,2), proba = 0.05)
#Otra forma de visualizar esto es combinar el biplot y la importancia de las componentes en el que los atributos con puntuaciones cos2 similares tendrán colores similares
fviz_pca_var(comps, col.var = "cos2",                        #replicar esta grafica con pca_comps en lugar
#del parametro comps.
gradient.cols = c("black", "orange", "green"),
repel = TRUE)
#Otra forma de visualizar esto es combinar el biplot y la importancia de las componentes en el que los atributos con puntuaciones cos2 similares tendrán colores similares
fviz_pca_var(comps, col.var = "cos2",                        #replicar esta grafica con pca_comps en lugar
#del parametro comps.
gradient.cols = c("black", "orange", "green"),
repel = TRUE)
# definimos los datos que usara el modelo
#variables originales
datos <- student_scores[c(vars_predict, dependiente)]
fit_model <- lm(weekly_self_study_hours ~., data = datos)
colinearidad <- data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad
#componentes principales
data2 <- cbind(student_scores[,dependiente],comps$scores)
colnames(data2) <- c('weekly_self_study_hours','comp1','comp2','comp3','comp4','comp5','comp6','comp7')
fit_model2 <- lm(weekly_self_study_hours ~., data = data2)
knitr::opts_chunk$set(echo = T, fig.width = 6, fig.height = 3.5)
#rm(list = ls())
pacman::p_load(tidyverse,
kableExtra,
cowplot,
stargazer,knitr,viridis,dplyr,readr,scales,quantmod,texreg,tinytex,
tidyr, imager,lubridate,tseries, astsa, growthrates, tis, dynlm,
readxl, foreign, hrbthemes, gtsummary, corrplot, lm.beta, ggfortify,
AER, lmtest, sandwich,GGally, ggplot2, car, psych, FactoMineR, factoextra,
caret, MASS, repr,scatterplot3d)
source("funciones.R") #funciones auxiliares prediseñadas
#Cargamos la base de datos
student_scores <- read.csv("DataSets/student-scores.csv") #con read_csv no reconoce como numéricos
summary(student_scores) #Estadística descriptiva de los datos
tipoDatos <- sapply(student_scores, class) # Saber los tipos de datos
continuas <-  which(tipoDatos == "numeric") # continuas
enteras <- which(tipoDatos == "integer") # enteras
numericas <- c(continuas,enteras)
nominales <- which( tipoDatos == "factor") # categoricas
ordinales <- which( sapply(student_scores, is.ordered) )  # ordinales
categoricas <- c(nominales, ordinales)
vars_predict <- c('math_score','history_score','physics_score',"chemistry_score","biology_score","english_score","geography_score")  #covariables
dependiente <- "weekly_self_study_hours" #variable explicada o dependiente
multi.hist(student_scores[, vars_predict]) # Histogramas con formato de funciones.R
pairs(student_scores[,vars_predict])
#par(mfrow = c(3, 3))
plot(student_scores$math_score,col="red",main = "Calificaciones en Matematicas",ylab = "Score")
plot(student_scores$history_score,col="blue",main = "Calificaciones Historia",ylab = "Score")
plot(student_scores$physics_score,col="cyan",main = "Calificaciones Fisica",ylab = "Score")
plot(student_scores$chemistry_score,col="seagreen",main = "Calificaciones Quimica",ylab = "Score")
plot(student_scores$biology_score,col="green",main = "Calificaciones Biologia",ylab = "Score")
plot(student_scores$english_score,col="magenta",main = "Calificaciones Ingles",ylab = "Score")
plot(student_scores$geography_score,col="orange",main = "Calificaciones Geografia",ylab = "Score")
par(bty = "n")
boxplot(student_scores[,vars_predict],main = "Boxplot de variables predictoras",las = 3,cex=0.6,cex.main = 0.8,cex.axis = 0.55, col = "red", border = "black")
KMO(student_scores[,vars_predict])
comps <- princomp(student_scores[,vars_predict])
summary(comps)
#### loadings:  Matriz Gamma
comps$loadings
#### scores: La muestra aleatoria de las ccomponentes ppales
head(comps$scores, 10)
#fit <- MVN::mvn(data = comps$scores, mvnTest = "hz", multivariateOutlierMethod = "quan")
ajuste <- MVN::mvn(data = as.matrix(comps$scores), mvnTest="hz", multivariateOutlierMethod="quan")
# definimos los datos que usara el modelo
#variables originales
datos <- student_scores[c(vars_predict, dependiente)]
fit_model <- lm(weekly_self_study_hours ~., data = datos)
colinearidad <- data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad
#componentes principales
data2 <- cbind(student_scores[,dependiente],comps$scores)
colnames(data2) <- c('weekly_self_study_hours','comp1','comp2','comp3','comp4','comp5','comp6','comp7')
fit_model2 <- lm(weekly_self_study_hours ~., data = data2)
# definimos los datos que usara el modelo
#variables originales
datos <- student_scores[c(vars_predict, dependiente)]
fit_model <- lm(weekly_self_study_hours ~., data = datos)
colinearidad <- data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad
#componentes principales
data2 <- cbind(student_scores[,dependiente],comps$scores)
colnames(data2) <- c('weekly_self_study_hours','comp1','comp2','comp3','comp4','comp5','comp6','comp7')
fit_model2 <- lm(weekly_self_study_hours ~., data = data2)
View(data2)
# definimos los datos que usara el modelo
#variables originales
datos <- student_scores[c(vars_predict, dependiente)]
fit_model <- lm(weekly_self_study_hours ~., data = datos)
colinearidad <- data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad
#componentes principales
data2 <- cbind(student_scores[,dependiente],comps$scores)
colnames(data2) <- c('weekly_self_study_hours','comp1','comp2','comp3','comp4','comp5','comp6','comp7')
data2<-as.data.frame(data2)
fit_model2 <- lm(weekly_self_study_hours ~., data = data2)
colinearidad_check <- data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad_check
summary(fit_model2)
# definimos los datos que usara el modelo
#variables originales
datos <- student_scores[c(vars_predict, dependiente)]
fit_model <- lm(weekly_self_study_hours ~., data = datos)
colinearidad <- data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad
#componentes principales
data2 <- cbind(student_scores[,dependiente],comps$scores)
colnames(data2) <- c('weekly_self_study_hours','comp1','comp2','comp3','comp4','comp5','comp6','comp7')
data2<-as.data.frame(data2)
fit_model2 <- lm(weekly_self_study_hours ~., data = data2)
colinearidad_check <- data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad_check
# definimos los datos que usara el modelo
#variables originales
datos <- student_scores[c(vars_predict, dependiente)]
fit_model <- lm(weekly_self_study_hours ~., data = datos)
colinearidad <- data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad
#componentes principales
data2 <- cbind(student_scores[,dependiente],comps$scores)
colnames(data2) <- c('weekly_self_study_hours','comp1','comp2','comp3','comp4','comp5','comp6','comp7')
data2<-as.data.frame(data2)
fit_model2 <- lm(weekly_self_study_hours ~., data = data2)
data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad_check
# definimos los datos que usara el modelo
#variables originales
datos <- student_scores[c(vars_predict, dependiente)]
fit_model <- lm(weekly_self_study_hours ~., data = datos)
colinearidad <- data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad
#componentes principales
data2 <- cbind(student_scores[,dependiente],comps$scores)
colnames(data2) <- c('weekly_self_study_hours','comp1','comp2','comp3','comp4','comp5','comp6','comp7')
data2<-as.data.frame(data2)
fit_model2 <- lm(weekly_self_study_hours ~., data = data2)
colinearidad_check <- data.frame(Variance_Inflation_Factor = vif(fit_model));
colinearidad_check
# definimos los datos que usara el modelo
#variables originales
datos <- student_scores[c(vars_predict, dependiente)]
fit_model <- lm(weekly_self_study_hours ~., data = datos)
colinearidad <- data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad
#componentes principales
data2 <- cbind(student_scores[,dependiente],comps$scores)
colnames(data2) <- c('weekly_self_study_hours','comp1','comp2','comp3','comp4','comp5','comp6','comp7')
data2<-as.data.frame(data2)
fit_model2 <- lm(weekly_self_study_hours ~., data = data2)
colinearidad_check <- data.frame(Variance_Inflation_Factor = vif(fit_model))
colinearidad_check
# definimos los datos que usara el modelo
#variables originales
datos <- student_scores[c(vars_predict, dependiente)]
fit_model <- lm(weekly_self_study_hours ~., data = datos)
colinearidad <- data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad
#componentes principales
data2 <- cbind(student_scores[,dependiente],comps$scores)
colnames(data2) <- c('weekly_self_study_hours','comp1','comp2','comp3','comp4','comp5','comp6','comp7')
data2<-as.data.frame(data2)
fit_model2 <- lm(weekly_self_study_hours ~., data = data2)
colinearidad_check <- data.frame(Variance_Inflation_Factor = vif(fit_model))
#colinearidad_check
summary(fit_model2)
summary(fit_model)
#componentes principales
data2 <- cbind(student_scores[,dependiente],comps$scores)
colnames(data2) <- c('weekly_self_study_hours','comp1','comp2','comp3','comp4','comp5','comp6','comp7')
data2<-as.data.frame(data2)
fit_model2 <- lm(weekly_self_study_hours ~., data = data2)
colinearidad_check <- data.frame(Variance_Inflation_Factor = vif(fit_model2))
#componentes principales
data2 <- cbind(student_scores[,dependiente],comps$scores)
colnames(data2) <- c('weekly_self_study_hours','comp1','comp2','comp3','comp4','comp5','comp6','comp7')
data2<-as.data.frame(data2)
fit_model2 <- lm(weekly_self_study_hours ~., data = data2)
colinearidad_check <- data.frame(Variance_Inflation_Factor = vif(fit_model2)); colinearidad_check
knitr::opts_chunk$set(echo = T, fig.width = 6, fig.height = 3.5)
#rm(list = ls())
pacman::p_load(tidyverse,
kableExtra,
cowplot,
stargazer,knitr,viridis,dplyr,readr,scales,quantmod,texreg,tinytex,
tidyr, imager,lubridate,tseries, astsa, growthrates, tis, dynlm,
readxl, foreign, hrbthemes, gtsummary, corrplot, lm.beta, ggfortify,
AER, lmtest, sandwich,GGally, ggplot2, car, psych, FactoMineR, factoextra,
caret, MASS, repr,scatterplot3d)
source("funciones.R") #funciones auxiliares prediseñadas
#Cargamos la base de datos
student_scores <- read.csv("DataSets/student-scores.csv") #con read_csv no reconoce como numéricos
summary(student_scores) #Estadística descriptiva de los datos
tipoDatos <- sapply(student_scores, class) # Saber los tipos de datos
continuas <-  which(tipoDatos == "numeric") # continuas
enteras <- which(tipoDatos == "integer") # enteras
numericas <- c(continuas,enteras)
nominales <- which( tipoDatos == "factor") # categoricas
ordinales <- which( sapply(student_scores, is.ordered) )  # ordinales
categoricas <- c(nominales, ordinales)
vars_predict <- c('math_score','history_score','physics_score',"chemistry_score","biology_score","english_score","geography_score")  #covariables
dependiente <- "weekly_self_study_hours" #variable explicada o dependiente
multi.hist(student_scores[, vars_predict]) # Histogramas con formato de funciones.R
pairs(student_scores[,vars_predict])
#par(mfrow = c(3, 3))
plot(student_scores$math_score,col="red",main = "Calificaciones en Matematicas",ylab = "Score")
plot(student_scores$history_score,col="blue",main = "Calificaciones Historia",ylab = "Score")
plot(student_scores$physics_score,col="cyan",main = "Calificaciones Fisica",ylab = "Score")
plot(student_scores$chemistry_score,col="seagreen",main = "Calificaciones Quimica",ylab = "Score")
plot(student_scores$biology_score,col="green",main = "Calificaciones Biologia",ylab = "Score")
plot(student_scores$english_score,col="magenta",main = "Calificaciones Ingles",ylab = "Score")
plot(student_scores$geography_score,col="orange",main = "Calificaciones Geografia",ylab = "Score")
par(bty = "n")
boxplot(student_scores[,vars_predict],main = "Boxplot de variables predictoras",las = 3,cex=0.6,cex.main = 0.8,cex.axis = 0.55, col = "red", border = "black")
KMO(student_scores[,vars_predict])
comps <- princomp(student_scores[,vars_predict])
summary(comps)
#### loadings:  Matriz Gamma
comps$loadings
#### scores: La muestra aleatoria de las ccomponentes ppales
head(comps$scores, 10)
#fit <- MVN::mvn(data = comps$scores, mvnTest = "hz", multivariateOutlierMethod = "quan")
ajuste <- MVN::mvn(data = as.matrix(comps$scores), mvnTest="hz", multivariateOutlierMethod="quan")
#fit <- MVN::mvn(data = comps$scores, mvnTest = "hz", multivariateOutlierMethod = "quan")
scores_matrix<-as.matrix(comps$scores)
ajuste <- MVN::mvn(data = as.matrix(comps$scores), mvnTest="hz", multivariateOutlierMethod="quan")
View(scores_matrix)
#fit <- MVN::mvn(data = comps$scores, mvnTest = "hz", multivariateOutlierMethod = "quan")
scores_matrix<-as.matrix(comps$scores)
ajuste <- MVN::mvn(data = scores_matrix, mvnTest="hz", multivariateOutlierMethod="quan")
#fit <- MVN::mvn(data = comps$scores, mvnTest = "hz", multivariateOutlierMethod = "quan")
scores_matrix<-as.matrix(comps$scores)
names(scores_matrix)<-c("comp1", "comp2","comp3", "comp4" , "comp5","comp6", "comp7" )
ajuste <- MVN::mvn(data = scores_matrix, mvnTest="hz", multivariateOutlierMethod="quan")
View(scores_matrix)
#fit <- MVN::mvn(data = comps$scores, mvnTest = "hz", multivariateOutlierMethod = "quan")
scores_matrix<-as.matrix(comps$scores)
scores_matrix<-as.data.frame(scores_matrix)
names(scores_matrix)<-c("comp1", "comp2","comp3", "comp4" , "comp5","comp6", "comp7" )
ajuste <- MVN::mvn(data = scores_matrix, mvnTest="hz", multivariateOutlierMethod="quan")
View(scores_matrix)
ajuste$multivariateNormality
ajuste$univariateNormality
knitr::opts_chunk$set(echo = T, fig.width = 6, fig.height = 3.5)
#rm(list = ls())
pacman::p_load(tidyverse,
kableExtra,
cowplot,
stargazer,knitr,viridis,dplyr,readr,scales,quantmod,texreg,tinytex,
tidyr, imager,lubridate,tseries, astsa, growthrates, tis, dynlm,
readxl, foreign, hrbthemes, gtsummary, corrplot, lm.beta, ggfortify,
AER, lmtest, sandwich,GGally, ggplot2, car, psych, FactoMineR, factoextra,
caret, MASS, repr,scatterplot3d)
source("funciones.R") #funciones auxiliares prediseñadas
#Cargamos la base de datos
student_scores <- read.csv("DataSets/student-scores.csv") #con read_csv no reconoce como numéricos
summary(student_scores) #Estadística descriptiva de los datos
tipoDatos <- sapply(student_scores, class) # Saber los tipos de datos
continuas <-  which(tipoDatos == "numeric") # continuas
enteras <- which(tipoDatos == "integer") # enteras
numericas <- c(continuas,enteras)
nominales <- which( tipoDatos == "factor") # categoricas
ordinales <- which( sapply(student_scores, is.ordered) )  # ordinales
categoricas <- c(nominales, ordinales)
vars_predict <- c('math_score','history_score','physics_score',"chemistry_score","biology_score","english_score","geography_score")  #covariables
dependiente <- "weekly_self_study_hours" #variable explicada o dependiente
multi.hist(student_scores[, vars_predict]) # Histogramas con formato de funciones.R
pairs(student_scores[,vars_predict])
#par(mfrow = c(3, 3))
plot(student_scores$math_score,col="red",main = "Calificaciones en Matematicas",ylab = "Score")
plot(student_scores$history_score,col="blue",main = "Calificaciones Historia",ylab = "Score")
plot(student_scores$physics_score,col="cyan",main = "Calificaciones Fisica",ylab = "Score")
plot(student_scores$chemistry_score,col="seagreen",main = "Calificaciones Quimica",ylab = "Score")
plot(student_scores$biology_score,col="green",main = "Calificaciones Biologia",ylab = "Score")
plot(student_scores$english_score,col="magenta",main = "Calificaciones Ingles",ylab = "Score")
plot(student_scores$geography_score,col="orange",main = "Calificaciones Geografia",ylab = "Score")
par(bty = "n")
boxplot(student_scores[,vars_predict],main = "Boxplot de variables predictoras",las = 3,cex=0.6,cex.main = 0.8,cex.axis = 0.55, col = "red", border = "black")
KMO(student_scores[,vars_predict])
comps <- princomp(student_scores[,vars_predict])
summary(comps)
#### loadings:  Matriz Gamma
comps$loadings
#### scores: La muestra aleatoria de las ccomponentes ppales
head(comps$scores, 10)
#fit <- MVN::mvn(data = comps$scores, mvnTest = "hz", multivariateOutlierMethod = "quan")
scores_matrix<-as.matrix(comps$scores)
scores_matrix<-as.data.frame(scores_matrix)
names(scores_matrix)<-c("comp1", "comp2","comp3", "comp4" , "comp5","comp6", "comp7" )
ajuste <- MVN::mvn(data = scores_matrix, mvnTest="hz", multivariateOutlierMethod="quan")
ajuste$multivariateNormality
ajuste$univariateNormality
plot(comps$scores[,c(1,2)], col = "blue4", main = "Gráfico con 2 componentes")
scatterplot3d(comps$scores[,c(1,3)], color="steelblue")
biplot(comps)
pca_comps <- PCA(student_scores[,vars_predict],scale.unit = T, ncp = 3, graph = T) #FactoMineR package
fviz_cos2(pca_comps,choice = "var",axes = 2)#factoextra package
pca_comps$desc <- dimdesc(pca_comps, axes = c(1,2), proba = 0.05)
pca_comps$desc$Dim.1
pca_comps$desc$Dim.2
fviz_pca_var(comps, col.var = "cos2",                        #replicar esta grafica con pca_comps en lugar
#del parametro comps.
gradient.cols = c("black", "orange", "green"),
repel = TRUE)
# definimos los datos que usara el modelo
#variables originales
datos <- student_scores[c(vars_predict, dependiente)]
fit_model <- lm(weekly_self_study_hours ~., data = datos)
colinearidad <- data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad
summary(fit_model)
#componentes principales
data2 <- cbind(student_scores[,dependiente],comps$scores)
colnames(data2) <- c('weekly_self_study_hours','comp1','comp2','comp3','comp4','comp5','comp6','comp7')
data2<-as.data.frame(data2)
fit_model2 <- lm(weekly_self_study_hours ~., data = data2)
colinearidad_check <- data.frame(Variance_Inflation_Factor = vif(fit_model2)); colinearidad_check
summary(fit_model2)
knitr::opts_chunk$set(echo = T, fig.width = 6, fig.height = 3.5)
#rm(list = ls())
pacman::p_load(tidyverse,
kableExtra,
cowplot,
stargazer,knitr,viridis,dplyr,readr,scales,quantmod,texreg,tinytex,
tidyr, imager,lubridate,tseries, astsa, growthrates, tis, dynlm,
readxl, foreign, hrbthemes, gtsummary, corrplot, lm.beta, ggfortify,
AER, lmtest, sandwich,GGally, ggplot2, car, psych, FactoMineR, factoextra,
caret, MASS, repr,scatterplot3d)
source("funciones.R") #funciones auxiliares prediseñadas
#Cargamos la base de datos
student_scores <- read.csv("DataSets/student-scores.csv") #con read_csv no reconoce como numéricos
summary(student_scores) #Estadística descriptiva de los datos
tipoDatos <- sapply(student_scores, class) # Saber los tipos de datos
continuas <-  which(tipoDatos == "numeric") # continuas
enteras <- which(tipoDatos == "integer") # enteras
numericas <- c(continuas,enteras)
nominales <- which( tipoDatos == "factor") # categoricas
ordinales <- which( sapply(student_scores, is.ordered) )  # ordinales
categoricas <- c(nominales, ordinales)
vars_predict <- c('math_score','history_score','physics_score',"chemistry_score","biology_score","english_score","geography_score")  #covariables
dependiente <- "weekly_self_study_hours" #variable explicada o dependiente
multi.hist(student_scores[, vars_predict]) # Histogramas con formato de funciones.R
pairs(student_scores[,vars_predict])
#par(mfrow = c(3, 3))
plot(student_scores$math_score,col="red",main = "Calificaciones en Matematicas",ylab = "Score")
plot(student_scores$history_score,col="blue",main = "Calificaciones Historia",ylab = "Score")
plot(student_scores$physics_score,col="cyan",main = "Calificaciones Fisica",ylab = "Score")
plot(student_scores$chemistry_score,col="seagreen",main = "Calificaciones Quimica",ylab = "Score")
plot(student_scores$biology_score,col="green",main = "Calificaciones Biologia",ylab = "Score")
plot(student_scores$english_score,col="magenta",main = "Calificaciones Ingles",ylab = "Score")
plot(student_scores$geography_score,col="orange",main = "Calificaciones Geografia",ylab = "Score")
par(bty = "n")
boxplot(student_scores[,vars_predict],main = "Boxplot de variables predictoras",las = 3,cex=0.6,cex.main = 0.8,cex.axis = 0.55, col = "red", border = "black")
KMO(student_scores[,vars_predict])
# definimos los datos que usara el modelo
#variables originales
datos <- student_scores[c(vars_predict, dependiente)]
fit_model <- lm(weekly_self_study_hours ~., data = datos)
colinearidad <- data.frame(Variance_Inflation_Factor = vif(fit_model));colinearidad
